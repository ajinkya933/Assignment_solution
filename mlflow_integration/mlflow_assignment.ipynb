{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3481 1021\n",
      "generated final dataframe\n",
      "all principle components =  0.9013876792494665 0.053136225084459206 0.01570821263396708 0.008323489056514435 0.004122294060626489 0.002990141273927295 0.002152948643757099 0.001581366443705649 0.0011379404988639593 0.0009993315058113817\n",
      "selected [90.13876792494665, 5.3136225084459205, 1.570821263396708]\n",
      "*********FINISHED*********\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "import json\n",
    "# import plotly.express as px\n",
    "import mlflow\n",
    "import requests\n",
    "import pandas as pd    \n",
    "import logging\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "storage_bucket = \"/Users/ajinkyabobade/Documents/1-master/folder2/mlruns_mydb\"\n",
    "\n",
    "########################################################\n",
    "#                Log image height x width\n",
    "########################################################\n",
    "\n",
    "# Setting a place for mlflow to store tracking and artifacts\n",
    "# mlflow.set_tracking_uri('/Users/ajinkyabobade/Documents/1-master/folder2/mlruns')\n",
    "\n",
    "mlflow.set_tracking_uri('http://0.0.0.0:8000')\n",
    "# Set an experiment name\n",
    "experiment_name = \"experiment_test_mumbai_tile\"\n",
    "## check if the experiment already exists\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "    mlflow.create_experiment(name=experiment_name,artifact_location=storage_bucket) \n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id = experiment.experiment_id,run_name= f\"run_{experiment_name}\") :\n",
    "    \n",
    "    import rasterio\n",
    "    src = rasterio.open('01.TIF')\n",
    "    array = src.read(1)\n",
    "\n",
    "    height = array.shape[0]\n",
    "    width =  array.shape[1]\n",
    "\n",
    "    print(height,width)\n",
    "\n",
    "    mlflow.log_param(\"Image height\",height)\n",
    "    mlflow.log_param(\"Image width\",width)\n",
    "\n",
    "    # Extract non zero values from image and note the \n",
    "    # index of pixel having non zero values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ########################################################\n",
    "    #                Log Principle components \n",
    "    ########################################################\n",
    "\n",
    "    from non_zero_dataframe import sort_tif\n",
    "    final = sort_tif()\n",
    "    # final.to_csv(\"non_zero_bands.csv\")\n",
    "    # mlflow.log_artifact(\"./non_zero.csv\")\n",
    "\n",
    "\n",
    "    print(\"generated final dataframe\")\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    n=[]\n",
    "    ind=[]\n",
    "    for i in range(242):     # 242 = number of bands\n",
    "        n.append(i+1)\n",
    "    for i in range(242):\n",
    "        ind.append('band'+str(n[i]))\n",
    "\n",
    "    features = ind\n",
    "    x = final.loc[:, features].values\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler_model = MinMaxScaler()\n",
    "    scaler_model.fit(x.astype(float))\n",
    "    x=scaler_model.transform(x)\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "    ## Finding the principle components\n",
    "    pca = PCA(n_components=10)\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    ev=pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "    print(\"all principle components = \", ev[0],ev[1],ev[2],ev[3],ev[4],ev[5],ev[6],ev[7],ev[8],ev[9])\n",
    "\n",
    "    selected_PC=[]\n",
    "    for elem in ev:\n",
    "        comp = elem * 100\n",
    "#         mlflow.log_metric(\"PCA_all\",comp)\n",
    "\n",
    "        if comp > 1:\n",
    "            selected_PC.append(comp)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"selected\", selected_PC)\n",
    "    pca_selected_components = len(selected_PC)\n",
    "\n",
    "#     from pandas import DataFrame\n",
    "#     df = DataFrame (ev,columns=['PC'])\n",
    "#     df2 = DataFrame (selected_PC, columns=['selected PC'])\n",
    "#     # print (df)\n",
    "#     df.to_csv('all_principle_components.csv')\n",
    "#     df2.to_csv('selected_principle_components.csv')\n",
    "\n",
    "\n",
    "    # mlflow.log_artifact(\"./all_principle_components.csv\")\n",
    "#     mlflow.log_artifact(\"./selected_principle_components.csv\")\n",
    "    mlflow.log_param(\"pca_all_components\",10)\n",
    "    mlflow.log_param(\"pca_selected_components\", pca_selected_components)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ########################################################\n",
    "    #                Log KNN\n",
    "    ########################################################\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components = pca_selected_components)\n",
    "    dt = pca.fit_transform(final.iloc[:, :-1].values)\n",
    "    q = pd.concat([pd.DataFrame(data = dt)] )\n",
    "    q.to_csv('pca_output.csv')\n",
    "    mlflow.log_artifact(\"./pca_output.csv\")\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    kmeans = KMeans(n_clusters=3)\n",
    "    kmeans = kmeans.fit(q)\n",
    "    labels = kmeans.predict(q)\n",
    "    mlflow.log_metric(\"Knn_clusters\",3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ########################################################\n",
    "    #                Log image output\n",
    "    ########################################################\n",
    "\n",
    "    index = final.index.tolist() \n",
    "    a= np.array(index)\n",
    "    dataset = pd.DataFrame({'count': a, 'labels': labels})\n",
    "    dataset.set_index('count', inplace = True)\n",
    "    res = dataset['labels'].value_counts()\n",
    "\n",
    "    def reshaped_coords(a):\n",
    "        '''\n",
    "            reshaped_coords takes in index of a label and outputs\n",
    "            its pixel location on orignal image\n",
    "        '''\n",
    "        q,r = divmod(a,width)\n",
    "        y_coord = q\n",
    "        x_coord = r\n",
    "        return (x_coord, y_coord)\n",
    "\n",
    "    Index_label_class1 = dataset[dataset['labels']==0].index.tolist()  \n",
    "    Index_label_class2 = dataset[dataset['labels']==1].index.tolist() \n",
    "    Index_label_class3 = dataset[dataset['labels']==2].index.tolist() \n",
    "#     Index_label_class4 = dataset[dataset['labels']==3].index.tolist() \n",
    "\n",
    "\n",
    "    class_1_list=[]\n",
    "    for values in Index_label_class1:\n",
    "      coords = reshaped_coords(values)\n",
    "      class_1_list.append(coords)\n",
    "\n",
    "    class_2_list=[]\n",
    "    for values in Index_label_class2:\n",
    "      coords = reshaped_coords(values)\n",
    "      class_2_list.append(coords)\n",
    "\n",
    "    class_3_list=[]\n",
    "    for values in Index_label_class3:\n",
    "      coords = reshaped_coords(values)\n",
    "      class_3_list.append(coords)\n",
    "\n",
    "#     class_4_list=[]\n",
    "#     for values in Index_label_class4:\n",
    "#       coords = reshaped_coords(values)\n",
    "#       class_4_list.append(coords)\n",
    "\n",
    "\n",
    "\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    # width = 1021\n",
    "    # height = 3481\n",
    "    #3481, 1021\n",
    "    # Make empty black image of size (100,100)\n",
    "    img = np.zeros((height, width, 3), np.uint8)\n",
    "\n",
    "    red = [0,0,255]\n",
    "    green = [0,255,0]\n",
    "    blue = [255,0,0]\n",
    "    darkgreen = [0,51,0]\n",
    "    for values in class_1_list:\n",
    "    #   print(values[1], values[0])\n",
    "\n",
    "      img[values[1],values[0]] = blue\n",
    "\n",
    "    cv2.imwrite('img1.png', img)\n",
    "\n",
    "    for values in class_2_list:\n",
    "    #   print(values[1], values[0])\n",
    "\n",
    "      img[values[1],values[0]] = green\n",
    "\n",
    "    cv2.imwrite('img2.png', img)\n",
    "\n",
    "\n",
    "    for values in class_3_list:\n",
    "    #   print(values[1], values[0])\n",
    "\n",
    "      img[values[1],values[0]] = red\n",
    "\n",
    "    cv2.imwrite('img3.png', img)\n",
    "\n",
    "\n",
    "#     for values in class_4_list:\n",
    "#     #   print(values[1], values[0])\n",
    "\n",
    "#       img[values[1],values[0]] = darkgreen\n",
    "\n",
    "#     cv2.imwrite('img4.png', img)\n",
    "    print(\"*********FINISHED*********\")\n",
    "\n",
    "\n",
    "    mlflow.log_artifact(\"./img3.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
